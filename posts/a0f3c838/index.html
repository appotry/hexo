<!DOCTYPE HTML><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="utf-8"><meta name="keywords" content="ai,face, deep learning"><meta name="description" content="深度学习之视频人脸识别系列，介绍了人脸识别领域的一些基本概念，分析了深度学习在人脸识别的基本流程，并总结了近年来科研领域的研究进展，最后分析了静态数据与视频动态数据在人脸识别技术上的差异。"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="apple-mobile-web-app-title" content="夜法之书"><meta name="theme-color" content="#7e9fc4"><meta name="msapplication-TileImage" content="/medias/icons/android-chrome-192x192.png"><meta name="msapplication-TileColor" content="#7e9fc4"><meta http-equiv="Content-Security-Policy" content="default-src * vitals.vercel-insights.com 'unsafe-inline' 'unsafe-eval'; script-src * 'unsafe-inline' 'unsafe-eval'; connect-src * 'unsafe-inline'; img-src * data: blob: 'unsafe-inline'; font-src * data: blob: 'unsafe-inline'; frame-src *;style-src * 'unsafe-inline';"><link rel="apple-touch-icon" href="/medias/icons/apple-touch-icon.png"><link rel="mask-icon" href="/medias/icons/android-chrome-512x512.svg" color="#000000"><meta name="referrer" content="no-referrer-when-downgrade"><title>深度学习之视频人脸识别系列 | 夜法之书</title><link rel="manifest" href="/manifest.json"><link rel="icon" type="image/webp" href="/favicon.webp"><link href="//cimg1.17lai.fun" rel="preconnect" crossorigin><link href="https://live2dapi.17lai.site" rel="preconnect" crossorigin><link href="https://live2dapi.17lai.site" rel="dns-prefetch" crossorigin><link href="//cdn.webpushr.com" rel="preconnect" crossorigin><link href="//bot.webpushr.com" rel="preconnect" crossorigin><link href="//analytics.webpushr.com" rel="preconnect" crossorigin><link href="https://waline.17lai.site" rel="preconnect" crossorigin><link href="https://waline.17lai.site" rel="dns-prefetch" crossorigin><link rel="alternate" type="application/atom+xml" title="所有订阅ATOM--夜法之书" href="https://blog.17lai.site/atom.xml"><link rel="alternate" type="application/rss+xml" title="所有订阅RSS2--夜法之书" href="https://blog.17lai.site/rss.xml"><link rel="alternate" type="application/json" title="所有订阅JSON--夜法之书" href="https://blog.17lai.site/feed.json"><script src="/libs/jquery/jquery.min.js?v=3.7.1"></script><link rel="stylesheet preload" as="style" type="text/css" href="/libs/awesome/css/all.min.css?v=5.15.4" importance="auto"><link rel="modulepreload" href="/libs/waline/waline.min.js?v=3.5.4" as="script" importance="low"><link rel="preload" href="/js/ana.js?v=1.1.0" as="script"><link rel="stylesheet preload" as="style" type="text/css" href="/libs/materialize/materialize.min.css?v=1.2.2"><link rel="stylesheet preload" as="style" type="text/css" href="/libs/aos/aos.min.css"><link rel="stylesheet preload" as="style" type="text/css" href="/libs/animate/animate.min.css" importance="low"><link rel="stylesheet preload" as="style" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css" importance="low"><link rel="stylesheet preload" as="style" type="text/css" href="/libs/jquery/jquery-ui.min.css?v=1.14.0" importance="low"><link rel="stylesheet preload" as="style" type="text/css" href="/css/main.css?v=1.0.0"><noscript><link rel="stylesheet" href="/libs/materialize/materialize.min.css?v=1.2.2"><link rel="stylesheet" href="/css/main.css?v=1.0.0"></noscript><link rel="stylesheet preload" as="style" href="/libs/tocbot/tocbot.min.css?v=4.35.0"><link rel="stylesheet preload" as="style" type="text/css" href="/libs/share/css/share.min.css?v=1.0.16"><link rel="stylesheet preload" as="style" type="text/css" href="/css/highlight.css?v=1.0.0" id="highlight-css"><link rel="stylesheet preload" as="style" type="text/css" href="/css/highlight-dark.css?v=1.0.0" id="highlight-css-dark"><link rel="stylesheet" href="/libs/waline/waline.min.css?v=3.5.4" importance="low"><link rel="modulepreload" href="/libs/waline/waline.min.js?v=3.5.4" as="script" importance="low"><link rel="stylesheet" type="text/css" href="/css/waline.css?v=1.0.2" media="none" onload='"all"!=media&&(media="all")'><link rel="preload" href="/libs/jquery/jquery.min.js?v=3.7.1" as="script" importance="high"><link rel="preload" href="/js/utils.js?v=1.1.1" as="script" importance="high"><link rel="preload" href="/js/color-schema.js?v=1.0.0" as="script" importance="high"><link rel="stylesheet preload" as="style" type="text/css" href="/libs/live2d/waifu.css" importance="low"><link rel="preload" href="/libs/materialize/materialize.min.js?v=1.2.2" as="script" importance="auto"><link rel="preload" href="/libs/masonry/masonry.pkgd.min.js?v=4.2.2" as="script"><link rel="preload" href="/libs/aos/aos.min.js" as="script"><link rel="preload" href="/libs/lightGallery/js/lightgallery-all.min.js" as="script" importance="low"><link rel="preload" href="/js/events.js?v=1.0.0" as="script"><link rel="preload" href="/js/plugins.js?v=1.0.1" as="script"><link rel="preload" href="/libs/scrollprogress/scrollProgress.min.js" as="script"><link rel="preload" href="/js/tw_cn.js?v=1.0.1" as="script" importance="low"><link rel="preload" href="/js/boot.js?v=1.0.0" as="script" importance="low"><link rel="preload" href="/libs/tocbot/tocbot.min.js?v=4.35.0" as="script"><link rel="preload" href="/libs/tag-common/index.js" as="script"><link rel="prefetch" as="script" href="/libs/share/js/social-share.min.js?v=1.0.16" importance="low"><link rel="preload" href="/libs/prism/components/prism-core.min.js?v=1.29.0" as="script"><link rel="preload" href="/libs/prism/plugins/autoloader/prism-autoloader.min.js" as="script"><link rel="stylesheet preload" as="style" type="text/css" href="/libs/prism/plugins/line-numbers/prism-line-numbers.min.css"><link rel="preload" href="/libs/prism/plugins/line-numbers/prism-line-numbers.min.js" as="script"><script id="matery-configs">var Matery=window.Matery||{};Matery.ctx=Object.assign({},Matery.ctx);var CONFIG={hostname:"blog.17lai.site",root:"/",version:"2.0.0",typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!1,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!1,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"TEXT"},copy_btn:!0,show_full:!0,show_expand:!0,shrink:!0,break:!1,image_caption:{enable:!0},fun_features:{typing:{enable:!0,typeSpeed:70,cursorChar:"_",loop:!1,scope:[]},anchorjs:{enable:!1,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!1,height_px:3,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},monitortext:{enable:!1,text:"你看不到我！"},videobg:{enable:!1,url:"/video_url.json?v=1.0.0"}},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"right",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:0,showToggleBtn:!0},outdate:{enable:!1,warning_day:365,error_day:3650},lazyload:{enable:!0,loading_img:"/medias_webp/loading2.svg",loading_img_dark:"/medias_webp/loading2-dark.svg",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,follow_dnt:!1,baidu:{enable:!1,id:"22cc5bdea6e529c1349d44b7306b3b8c"},google:{enable:!1,id:"G-JNYZP4ZLDJ"},gtag:{enable:!1,id:"G-JNYZP4ZLDJ"},umami:{enable:!0,url:"https://ana.17lai.site",id:"e532f69d-5606-40c9-9dbb-bfa04258384f"},tencent:{enable:!1,sid:null,cid:null},woyaola:{enable:!1,id:"JynRUZuReKUzZQSo",ck:"JynRUZuReKUzZQSo"},cnzz:{enable:!1,id:null},leancloud:{app_id:null,app_key:null,server_url:null,path:"window.location.pathname",ignore_local:!1}},statistics:{busuanziStatistics:{enable:!1,totalTraffic:!0,totalNumberOfvisitors:!0},umami:{enable:!0,totalTraffic:!0,totalNumberOfvisitors:!0,pageStats:!0,start_time:"2023-01-01T00:00:00.000Z",token:"OgIvVJnSmkB37SNyb9UYE33p9hKuI/6jodFSsENOJbyjfg+AG+lYaU499pgVo8gZ1uPIUu9mYMFOk0E9U5cFMbUvI2guPKZZHMxp/xs+1vWtaoV7055ou/e8Ig8Rpm23VRreWzvLZiu+TpbreotPGLXUCYLxUqeedDjKvFPb+Rx6D34/l+gEetxG/vbJJvfTgITk+snFv0zwxx9i2Ig8jhycilhDEhKKva/8L/0+uAewZ2i+6mq4Mn+s0UKfzXVCsDCJ08lJS9UcyjL5d8t5eZ8A2u1b3IV0ElqiaCepF7+HgmsTPR8c2h76Sf1yaUJa+0tPvMcRGLjClA5tFB3+N5hOF8anC072cw==",api_server:"https://ana.17lai.site",data_website_id:"e532f69d-5606-40c9-9dbb-bfa04258384f"}},search_path:"/local-search.xml"};if(CONFIG.web_analytics.follow_dnt){var dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack;Matery.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on"))}</script><script src="/js/utils.js?v=1.1.1"></script><script src="/js/color-schema.js?v=1.0.0"></script><link rel="stylesheet" href="/libs/prism/plugins/line-numbers/prism-line-numbers.min.css"><script async>var windowWidth=window.innerWidth,minFunWidth=1024;window.addEventListener("resize",(function(){windowWidth=window.innerWidth}));var supportsPassive=!1;try{var opts=Object.defineProperty({},"passive",{get:function(){supportsPassive=!0}});window.addEventListener("testpassive",null,opts),window.removeEventListener("testpassive",null,opts)}catch(n){}var runningOnBrowser="undefined"!=typeof window,isBot=runningOnBrowser&&!("onscroll"in window)||"undefined"!=typeof navigator&&/(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo|Google (Page Speed|Web Preview)/i.test(navigator.userAgent)</script><script async>const swUrl="/sw.js",swScope="/";(async()=>{if("serviceWorker"in navigator)try{const r=await navigator.serviceWorker.register(swUrl,{scope:"/"});console.log("[PWA]Service Worker registered:",r)}catch(r){console.error("[PWA]Service Worker registration failed:",r)}})()</script><script async>Matery.ctx.dnt||isBot||function(){var e=document.createElement("script");e.async=!0,e.defer=!0,e.dataset.cache=!0,e.dataset.websiteId="e532f69d-5606-40c9-9dbb-bfa04258384f",e.src="https://ana.17lai.site/script.js";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script>let HEXO_MMEDIA_DATA={js:[],css:[],aplayerData:[],metingData:[],artPlayerData:[],dplayerData:[]}</script><meta name="generator" content="Hexo 7.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img no-lazy src="/favicon.webp" width="108" height="108" style="width:40px;height:45px" class="logo-img" alt="LOGO"> <span class="logo-span">夜法之书</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse" aria-label="侧边菜单"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item menu-2d-home"><a href="/" class="nav-link"><i class="fas fa-home"></i> 首页</a></li><li class="hide-on-med-and-down nav-item menu-2d-nav"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://nav.17lai.site/" class="nav-link"><i class="fas fa-suitcase"></i> 导航</a></li><li class="hide-on-med-and-down nav-item menu-2d-sosuo"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://so.17lai.site/" class="nav-link"><i class="fas fa-mask"></i> SO</a></li><li class="hide-on-med-and-down nav-item menu-2d-media"><a href="#" class="nav-link"><i class="fas fa-music"></i> 多媒体 <i class="fas fa-chevron-down" aria-hidden="true"></i></a><ul class="sub-nav menus_item_child"><li class="menu-2d-musics"><a class="nav-link" href="/musics/"><i class="fas fa-music fa-fw" style="margin-top:-20px"></i> 音乐</a></li><li class="menu-2d-galleries"><a class="nav-link" href="/galleries/"><i class="fas fa-image fa-fw" style="margin-top:-20px"></i> 相册</a></li><li class="menu-2d-movies"><a class="nav-link" href="/movies/"><i class="fas fa-film fa-fw" style="margin-top:-20px"></i> 视频</a></li><li class="menu-2d-musicplayer"><a class="nav-link" target="_blank" rel="noopener external nofollow noreferrer" href="https://musicplayer.17lai.site/"><i class="fas fa-music fa-fw" style="margin-top:-20px"></i> 在线云音乐</a></li><li class="menu-2d-music"><a class="nav-link" target="_blank" rel="noopener external nofollow noreferrer" href="https://music.17lai.site/"><i class="fas fa-music fa-fw" style="margin-top:-20px"></i> 音乐播放器</a></li></ul></li><li class="hide-on-med-and-down nav-item menu-2d-posts"><a href="#" class="nav-link"><i class="fas fa-folder-plus"></i> 文章 <i class="fas fa-chevron-down" aria-hidden="true"></i></a><ul class="sub-nav menus_item_child"><li class="menu-2d-tags"><a class="nav-link" href="/tags/"><i class="fas fa-tags fa-fw" style="margin-top:-20px"></i> 标签</a></li><li class="menu-2d-categories"><a class="nav-link" href="/categories/"><i class="fas fa-bookmark fa-fw" style="margin-top:-20px"></i> 分类</a></li><li class="menu-2d-archives"><a class="nav-link" href="/archives/"><i class="fas fa-archive fa-fw" style="margin-top:-20px"></i> 归档</a></li></ul></li><li class="hide-on-med-and-down nav-item menu-2d-toolbox"><a href="#" class="nav-link"><i class="fas fa-toolbox"></i> 工具 <i class="fas fa-chevron-down" aria-hidden="true"></i></a><ul class="sub-nav menus_item_child"><li class="menu-2d-tg"><a class="nav-link" target="_blank" rel="noopener external nofollow noreferrer" href="https://t.me/chat_17laisite"><i class="fab fa-telegram-plane fa-fw" style="margin-top:-20px"></i> TG交流群</a></li><li class="menu-2d-linuxtool"><a class="nav-link" target="_blank" rel="noopener external nofollow noreferrer" href="https://linux-command.17lai.site/"><i class="fas fa-terminal fa-fw" style="margin-top:-20px"></i> Linux命令</a></li><li class="menu-2d-cheatsheets"><a class="nav-link" href="/dash/"><i class="fas fa-laptop-code fa-fw" style="margin-top:-20px"></i> 各种快查表</a></li><li class="menu-2d-onebox"><a class="nav-link" target="_blank" rel="noopener external nofollow noreferrer" href="https://alist.17lai.site/"><i class="fas fa-cloud fa-fw" style="margin-top:-20px"></i> 私人网盘</a></li><li class="menu-2d-staticnav"><a class="nav-link" href="/nav/"><i class="fas fa-tools fa-fw" style="margin-top:-20px"></i> 网址导航</a></li></ul></li><li class="hide-on-med-and-down nav-item menu-2d-mirror"><a href="#" class="nav-link"><i class="fas fa-link"></i> 镜像 <i class="fas fa-chevron-down" aria-hidden="true"></i></a><ul class="sub-nav menus_item_child"><li class="menu-2d-mirror-cf"><a class="nav-link" target="_blank" rel="noopener external nofollow noreferrer" href="https://cfblog.17lai.site/"><i class="fas fa-link fa-fw" style="margin-top:-20px"></i> CF镜像</a></li><li class="menu-2d-mirror-vps20"><a class="nav-link" target="_blank" rel="noopener" href="https://v20blog.17lai.site/"><i class="fas fa-link fa-fw" style="margin-top:-20px"></i> VPS镜像</a></li><li class="menu-2d-mirror-main"><a class="nav-link" href="https://blog.17lai.site/"><i class="fas fa-link fa-fw" style="margin-top:-20px"></i> 主站</a></li></ul></li><li class="hide-on-med-and-down nav-item menu-2d-friends"><a href="/friends/" class="nav-link"><i class="fas fa-link"></i> 友链</a></li><li class="hide-on-med-and-down nav-item menu-2d-msg"><a href="/msg/" class="nav-link"><i class="fas fa-comment-alt"></i> 留言</a></li><li class="hide-on-med-and-down nav-item menu-2d-about"><a href="/about/" class="nav-link"><i class="fas fa-user-circle"></i> 关于</a></li><li class="nav-item menu-2d-search"><a href="#searchModal" class="nav-link modal-trigger" data-umami-event-search="search modal click" onclick="handleSearchClick()"><i id="searchIcon" class="fas fa-search" title="搜索"></i></a></li><li class="nav-item menu-2d-dark" data-umami-event-color="color toggle" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" rel="external nofollow noreferrer" aria-label="Color Toggle">&nbsp; <i class="fas fa-sun" id="color-toggle-icon"></i>&nbsp;</a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><div><img src="/favicon.webp" width="108" height="108" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload style="width:45px;height:45px" class="logo-img circle responsive-img" alt="LOGO"><div class="logo-name">夜法之书</div><div class="logo-desc">~软件驱动世界~个人独立技术博客，关于Linux,开源，Nas，Docker，嵌入式，理财，健身等主题！</div></div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://nav.17lai.site/" class="waves-effect waves-light"><i class="fa-fw fas fa-suitcase"></i> 导航</a></li><li class="m-nav-item"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://so.17lai.site/" class="waves-effect waves-light"><i class="fa-fw fas fa-mask"></i> SO</a></li><li class="m-nav-item"><a href="javascript:;" rel="external nofollow noreferrer"><i class="fa-fw fas fa-music"></i> 多媒体 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/musics/" style="margin-left:75px"><i class="fas fa-music fa-fw" style="position:absolute;left:50px"></i> <span>音乐</span></a></li><li><a href="/galleries/" style="margin-left:75px"><i class="fas fa-image fa-fw" style="position:absolute;left:50px"></i> <span>相册</span></a></li><li><a href="/movies/" style="margin-left:75px"><i class="fas fa-film fa-fw" style="position:absolute;left:50px"></i> <span>视频</span></a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://musicplayer.17lai.site/" style="margin-left:75px"><i class="fas fa-music fa-fw" style="position:absolute;left:50px"></i> <span>在线云音乐</span></a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://music.17lai.site/" style="margin-left:75px"><i class="fas fa-music fa-fw" style="position:absolute;left:50px"></i> <span>音乐播放器</span></a></li></ul></li><li class="m-nav-item"><a href="javascript:;" rel="external nofollow noreferrer"><i class="fa-fw fas fa-folder-plus"></i> 文章 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/tags/" style="margin-left:75px"><i class="fas fa-tags fa-fw" style="position:absolute;left:50px"></i> <span>标签</span></a></li><li><a href="/categories/" style="margin-left:75px"><i class="fas fa-bookmark fa-fw" style="position:absolute;left:50px"></i> <span>分类</span></a></li><li><a href="/archives/" style="margin-left:75px"><i class="fas fa-archive fa-fw" style="position:absolute;left:50px"></i> <span>归档</span></a></li></ul></li><li class="m-nav-item"><a href="javascript:;" rel="external nofollow noreferrer"><i class="fa-fw fas fa-toolbox"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://t.me/chat_17laisite" style="margin-left:75px"><i class="fab fa-telegram-plane fa-fw" style="position:absolute;left:50px"></i> <span>TG交流群</span></a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://linux-command.17lai.site/" style="margin-left:75px"><i class="fas fa-terminal fa-fw" style="position:absolute;left:50px"></i> <span>Linux命令</span></a></li><li><a href="/dash/" style="margin-left:75px"><i class="fas fa-laptop-code fa-fw" style="position:absolute;left:50px"></i> <span>各种快查表</span></a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://alist.17lai.site/" style="margin-left:75px"><i class="fas fa-cloud fa-fw" style="position:absolute;left:50px"></i> <span>私人网盘</span></a></li><li><a href="/nav/" style="margin-left:75px"><i class="fas fa-tools fa-fw" style="position:absolute;left:50px"></i> <span>网址导航</span></a></li></ul></li><li class="m-nav-item"><a href="javascript:;" rel="external nofollow noreferrer"><i class="fa-fw fas fa-link"></i> 镜像 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://cfblog.17lai.site/" style="margin-left:75px"><i class="fas fa-link fa-fw" style="position:absolute;left:50px"></i> <span>CF镜像</span></a></li><li><a target="_blank" rel="noopener" href="https://v20blog.17lai.site/" style="margin-left:75px"><i class="fas fa-link fa-fw" style="position:absolute;left:50px"></i> <span>VPS镜像</span></a></li><li><a href="https://blog.17lai.site/" style="margin-left:75px"><i class="fas fa-link fa-fw" style="position:absolute;left:50px"></i> <span>主站</span></a></li></ul></li><li class="m-nav-item"><a href="/friends/" class="waves-effect waves-light"><i class="fa-fw fas fa-link"></i> 友链</a></li><li class="m-nav-item"><a href="/msg/" class="waves-effect waves-light"><i class="fa-fw fas fa-comment-alt"></i> 留言</a></li><li class="m-nav-item"><a href="/about/" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li></ul></div></div></nav></header><div id="banner" class="bg-cover pd-header post-cover" style="background-image:url(/medias_webp/cover/DeepLearning.webp)"><div class="bg-cover-before"></div><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand center"><h1 id="post-title" class="description center-align post-title"><span id="typed-strings"><span>深度学习之视频人脸识别系列</span> </span><span id="typed"></span></h1><div class="center-align"><div id="umami-page-views-container" class="post-meta" style="display:inline"><i class="far fa-eye fa-fw"></i>查阅:&nbsp;&nbsp; <span id="umami-page-views" style="display:none;min-width:2rem"></span> <i id="umami_pageviews_loading_icon" class="fas fa-sync fa-spin" style="display:inline-block;min-width:2rem"></i>&nbsp;&nbsp;</div><div id="waline_container_comment_count" class="post-meta" style="display:inline"><i class="far fa-comment fa-fw"></i>评论:&nbsp;&nbsp; <span id="waline_comments_count" class="waline-comment-count" data-path="/posts/a0f3c838/" style="display:none;min-width:2rem"></span> <i id="waline_commentcount_loading_icon" class="fas fa-sync fa-spin infinite-rotate" style="display:inline-block;min-width:2rem"></i>条</div></div></div></div></div></div><div class="bg-cover-after"></div></div><main class="post-container content"><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/ai/"><span class="chip bg-color">ai</span> </a><a href="/tags/face/"><span class="chip bg-color">face</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/ai/" class="post-category">ai</a><link rel="alternate dns-prefetch" type="application/atom+xml" title="分类订阅--ai" href="https://blog.17lai.site/categories/ai/atom.xml"></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i> <span>发布:&nbsp;&nbsp;</span><time datetime="2021-09-14 12:25" pubdate> 2021年9月14日 中午</time></div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i> <span>更新:&nbsp;&nbsp;</span><time datetime="2023-03-13 14:02" update> 2023年3月13日 下午</time></div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>字数:&nbsp;&nbsp; 8.7k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅时:&nbsp;&nbsp; 32 分</div><div id="read_mode" class="info-break-policy" style="display:inline"><i class="fas fa-expand-arrows-alt" title="【进入/离开】 阅读模式" aria-hidden="true"></i>&nbsp;&nbsp; <span title="【进入/离开】阅读模式" aria-hidden="true">阅读模式</span></div></div></div><hr class="clearfix"><div class="card-content article-card-content markdown-body"><div id="articleContent"><h2 id="系列1-简介">系列1 简介</h2><p>出品 | 磐创AI技术团队</p><p>【磐创AI导读】本文是深度学习之视频<a target="_blank" rel="noopener external nofollow noreferrer" href="https://cloud.tencent.com/product/facerecognition?from=10680">人脸识别</a>系列的第一篇文章，介绍了人脸识别领域的一些基本概念，分析了深度学习在人脸识别的基本流程，并总结了近年来科研领域的研究进展，最后分析了静态数据与视频动态数据在人脸识别技术上的差异。欢迎大家点击上方篮子关注我们的公众号：磐创AI。</p><h2 id="一、基本概念"><strong>一、基本概念</strong></h2><h3 id="1-人脸识别（face-identification）"><strong>1. 人脸识别（face identification）</strong></h3><p>人脸识别是1对n的比对，给定一张人脸图片，如何在n张人脸图片中找到同一张人脸图片，相对于一个分类问题，将一张人脸划分到n张人脸中的一张。类似于管理人员进行的人脸识别门禁系统。</p><h3 id="2-人脸验证（face-verification）"><strong>2.人脸验证（face verification）</strong></h3><p>人脸验证的1对1的比对，给定两张人脸图片，判断这两张人脸是否为同一人，类似于手机的人脸解锁系统，事先在手机在录入自己的脸部信息，然后在开锁时比对摄像头捕捉到的人脸是否与手机上录入的人脸为同一个人。</p><h3 id="3-人脸检测（face-detection）"><strong>3.人脸检测（face detection）</strong></h3><p>人脸检测是在一张图片中把人脸检测出来，即在图片上把人脸用矩形框出来，并得到矩形的坐标，如下图所示。</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914140027.png" width="1067" height="477" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><h3 id="4-人脸关键点检测"><strong>4. 人脸关键点检测</strong></h3><p>根据输入的人脸图像，识别出面部关键特征点，如眼睛、鼻尖、嘴角点、眉毛以及人脸各部件轮廓点的坐标，如下图所示。</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914140105.png" width="1097" height="391" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><h3 id="5-人脸矫正（人脸对齐）"><strong>5. 人脸矫正（人脸对齐）</strong></h3><p>通过人脸关键点检测得到人脸的关键点坐标，然后根据人脸的关键点坐标调整人脸的角度，使人脸对齐，由于输入图像的尺寸是大小不一的，人脸区域大小也不相同，角度不一样，所以要通过坐标变换，对人脸图像进行归一化操作，如下图所示。</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914140120.png" width="1095" height="394" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><h2 id="二、基于深度学习的人脸识别算法基本流程"><strong>二、基于深度学习的人脸识别算法基本流程</strong></h2><p>随着神经网络的迅速发展和其对图像数据的强大的特征提取，深度学习运用于人脸识别也成为热点研究方向；2014年的开山之作DeepFace，第一个真正将<a target="_blank" rel="noopener external nofollow noreferrer" href="https://cloud.tencent.com/solution/bigdata?from=10680">大数据</a>和深度学习结合应用于人脸识别与验证，确立人脸识别的常规流程：图片-&gt;人脸与关键点检测-&gt;人脸对齐-&gt;人脸表征（representation）-&gt;分类。首先将图片中的人脸检测处理并通过关键点进行对齐，如何输入到神经网络，得到特征向量，通过分类训练过程，该向量即为人脸的特征向量。要求出两张人脸的相似度即计算两个特征的向量度量之差，方法包括：SVM、SiameseNetwork、JointBayesian、L1距离、L2距离、cos距离等。</p><h2 id="三、科研领域近期进展"><strong>三、科研领域近期进展</strong></h2><p>科研领域近期进展主要集中于loss函数的研究，包括DeepId2（Contrastive Loss）、FaceNet（Triplet loss）、L-Softmax、SphereFace（A-Softmax）、Center Loss、L2-Softmax、NormFace、CosFace（AM-Softmax）、ArcFace（AA-Softmax）等。</p><h2 id="四、基于视频人脸识别和图片人脸识别的区别"><strong>四、基于视频人脸识别和图片人脸识别的区别</strong></h2><p><strong>（_该小结部分参考于博客园 - 米罗西<a target="_blank" rel="noopener external nofollow noreferrer" href="http://www.cnblogs.com/zhehan54/p/6727631.html_%EF%BC%89">http://www.cnblogs.com/zhehan54/p/6727631.html_）</a></strong></p><p>相对于图片数据，目前视频人脸识别有很多挑战，包括：（1）视频数据一般为户外，视频图像质量比较差；（2）人脸图像比较小且模糊；（3）视频人脸识别对实时性要求更高。</p><p>但是视频数据也有一些优越性，视频数据同时具有空间信息和时间信息，在时间和空间的联合空间中描述人脸和识别人脸会具有一定提升空间。在视频数据中人脸跟踪是一个提高识别的方法，首先检测出人脸，然后跟踪人脸特征随时间的变化。当捕捉到一帧比较好的图像时，再使用图片人脸识别算法进行识别。这类方法中跟踪和识别是单独进行的，时间信息只在跟踪阶段用到。</p><p>【总结】：本期文章主要介绍了基于深度学习的人脸识别算法的一些基本入门知识，下一期我给大家介绍人脸识别中获取神经网络输入的算法，即关于人脸检测、人脸关键点检测与人脸对齐的一些重要算法和相关论文解析。</p><h2 id="系列2-人脸检测与对齐">系列2 人脸检测与对齐</h2><h2 id="一、人脸检测与关键点检测"><strong>一、人脸检测与关键点检测</strong></h2><h3 id="1-问题描述："><strong>1. 问题描述：</strong></h3><p>人脸检测解决的问题为给定一张图片，输出图片中人脸的位置，即使用方框框住人脸，输出方框的左上角坐标和右下角坐标或者左上角坐标和长宽。算法难点包括：人脸大小差异、人脸遮挡、图片模糊、角度与姿态差异、表情差异等。而关键检测则是输出人脸关键点的坐标，如左眼（x1，y1）、右眼（x2，y2）、鼻子（x3，y3）、嘴巴左上角（x4，y4）、嘴巴右上角（x5，y5）等。</p><h3 id="2-深度学习相关算法："><strong>2. 深度学习相关算法：</strong></h3><h4 id="（1）Cascade-CNN"><strong>（1）Cascade CNN</strong></h4><p>Cascade CNN源于发表于2015年CVPR上的一篇论文A Convolutional Neural Network Cascade for Face Detection【2】，作者提出了一种级连的CNN网络结构用于人脸检测。算法主体框架是基于V-J的瀑布流思想【1】，是传统技术和深度网络相结合的一个代表，Cascade CNN包含了多个分类器，这些分类器使用级联结构进行组织，与V-J不同的地方在于Cascade CNN采用卷积网络作为每一级的分类器。整个网络的处理流程如下图所示：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914140330.png" width="1094" height="226" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>整个处理流程里包含了六个网络：12-net、12-calibration-net、24-net、24-calibration-net、48-net、48-calibration-net，其中三个二分类网络用于分类其是否为人脸，另外三个calibration网络用于矫正人脸框边界。其中第二个网络之后、第四个网络之后、第五个网络之后使用NMS算法过滤掉冗余的框。</p><p>12-net，24-net和48-net的网络结构如下图所示：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914140401.png" width="1055" height="493" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>13-12-calibration-net，24-calibration-net，48-calibration-net的结构如下图所示：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914140426.png" width="1105" height="449" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>该算法结合了V-J框架构造了级连的CNN网络结构并设计边界矫正网络用来专门矫正人脸框边界，在AFW数据集上准确率达到97.97%。</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914140457.png" width="1088" height="762" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><h4 id="（2）Faceness-Net"><strong>（2）Faceness-Net</strong></h4><p>Faceness-Net源于论文A convolutional neural network cascade for face detection【3】，该算法基于DCNN网络【5】的人脸局部特征分类器，算法首先进行人脸局部特征的检测，使用多个基于DCNN网络的facial parts分类器对人脸进行评估，然后根据每个部件的得分进行规则分析得到Proposal的人脸区域，然后从局部到整体得到人脸候选区域，再对人脸候选区域进行<a target="_blank" rel="noopener external nofollow noreferrer" href="https://cloud.tencent.com/product/facerecognition?from=10680">人脸识别</a>和矩形框坐标回归，该过程分为两个步骤。</p><p>第一个步骤：每个人脸局部特征使用attribute-aware网络检测并生成人脸局部图，其中一共五个特征属性： 头发、眼睛、鼻子、嘴巴、胡子。然后通过人脸局部图根据评分构建人脸候选区域，具体如下图所示：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914140529.png" width="2270" height="789" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>第二个步骤：训练一个多任务的卷积网络来完成人脸二分类和矩形框坐标回归，进一步提升其效果，具体如下图所示：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914140548.png" width="1098" height="353" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>Faceness从脸部特征的角度来解决人脸检测中的遮挡和姿态角度问题，其整体性能在当时是非常好的，在AFW数据集上准确率可以达到98.05%。</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914140611.png" width="1087" height="644" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><h4 id="（3）MTCNN"><strong>（3）MTCNN</strong></h4><p>MTCNN源于论文Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks【6】，是基于多任务级联卷积神经网络来解决人脸检测和对齐问题，同时输出图片的人脸矩阵框和关键点坐标（左眼、右眼、鼻子、嘴巴左上角、嘴巴右上角）。MTCNN为三阶的级联卷积神经网络，整体框架如下图所示：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914140644.png" width="729" height="842" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>输入阶段：为应对目标多尺度问题，将原始图像resize到不同尺寸，构建图像金字塔，作为三阶级联架构的输入，这样处理可以更好地检测大小不一的人脸。</p><p>第一阶段：通过一个全部由卷积层组成的CNN，取名P-Net，获取候选人脸框、关键点坐标和人脸分类（是人脸或不是），之后采用NMS过滤掉高重叠率的候选窗口。如下图所示：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914140717.png" width="859" height="344" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>第二阶段：第一阶段输出的候选人脸框作为更为复杂的R-Net网络的输入，R-Net进一步筛除大量错误的候选人脸框，同样也通过NMS过滤掉高重叠率的候选窗口。如下图所示：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914140741.png" width="907" height="327" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>第三阶段：与第二阶段类似，最终网络输出人脸框坐标、关键点坐标和人脸分类（是人脸或不是）。如下图所示：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914140801.png" width="1098" height="234" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>MTCNN通过三级的级联卷积神经网络对任务进行从粗到细的处理，还提出在线困难样本生成策略（online hard sample mining ）可以进一步提升性能。兼并了速度与准确率，速度在<a target="_blank" rel="noopener external nofollow noreferrer" href="https://cloud.tencent.com/product/gpu?from=10680">GPU</a>上可以达到99FPS，在 FDDB数据集上可以达到95.04准确率，具体如下图所示：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914140818.png" width="896" height="837" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><h2 id="二、人脸对齐（部分参考于GraceDD的博客文章）"><strong>二、人脸对齐（部分参考于GraceDD的博客文章）</strong></h2><p>人脸对齐通过人脸关键点检测得到人脸的关键点坐标，然后根据人脸的关键点坐标调整人脸的角度，使人脸对齐，由于输入图像的尺寸是大小不一的，人脸区域大小也不相同，角度不一样，所以要通过坐标变换，对人脸图像进行归一化操作。人脸关键点检测有很多算法可以使用包括：ASM、AAM、DCNN 、TCDCN 、MTCNN 、TCNN、TCNN等，这里就不详细介绍，主要说一下得到人脸关键点之后如何进行人脸对齐，是所有人脸达到归一化效果，该过程如下图所示：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914140841.png" width="1091" height="416" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>该过程涉及到图像的仿射变换，简单来说，“仿射变换”就是：“线性变换”+“平移”，即坐标的变换。假如我们希望人脸图片归一化为尺寸大小600<em>600，左眼位置在（180，200），右眼位置在（420，200）。 这样人脸中心在图像高度的1/3位置，并且两个眼睛保持水平，所以我们选择左眼角位置为( 0.3</em>width, height / 3 )，右眼角位置为（0.7*width , height / 3） 。</p><p>利用这两个点计算图像的变换矩阵（similarity transform），该矩阵是一个2*3的矩阵，如下：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652.png" width="296" height="92" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>如果我们想对一个矩形进行变换，其中x、y方向的缩放因为分别为sx，sy，同时旋转一个角度 ，然后再在x方向平移tx, 在y方向平移ty</p><p>利用opencv的estimateRigidTransform方法，可以获得这样的变换矩阵，但遗憾的是，estimateRigidTransform至少需要三个点，所以我们需要构选第三个点，构造方法是用第三个点与已有的两个点构成等边三角形，这样第三个点的坐标为：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914140918.png" width="662" height="133" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>代码如下：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914140938.png" width="988" height="378" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>经过上一步的处理之后，所有的图像都变成一样大小，并且又三个关键点的位置是保持一致的，但因为除了三个点对齐了之外，其他点并没有对齐。所以根据得到的变换矩阵对剩下所有的点进行仿射变换，opencv代码如下所示：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914141001.png" width="1026" height="39" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>img为输入图像;</p><p>warped为变换后图像，类型与src一致;</p><p>M为变换矩阵，需要通过其它函数获得，当然也可以手动输入;</p><p>Image_size为输出图像的大小;</p><h2 id="三、-总结"><strong>三、 总结</strong></h2><p>本期文章主要介绍了人脸检测与对齐的相关算法，下一期我给大家介绍一下人脸表征的相关算法，即通过深度学习提取人脸特征，通过比较人脸特征进行人脸识别与验证。</p><h3 id="参考文献："><strong>参考文献：</strong></h3><ul><li>【1】 <a target="_blank" rel="noopener external nofollow noreferrer" href="http://S.Z.Li">S.Z.Li</a>, L.Zhu, Z.Q.Zhang, A.Blake, H.J.Zhang, H.Y.Shum. Statistical learning of multi-view face detection. In: Proceedings of the 7-th European Conference on Computer Vision. Copenhagen, Denmark: Springer, 2002.67-81.</li><li>【2】Li H, Lin Z, Shen X, et al. A convolutional neural network cascade for face detection[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 5325-5334.</li><li>【3】Yang S, Luo P, Loy C C, et al. Faceness-Net: Face detection through deep facial part responses[J]. IEEE transactions on pattern analysis and machine intelligence, 2017.</li><li>【4】Yang S, Luo P, Loy C C, et al. From facial parts responses to face detection: A deep learning approach[C]//Proceedings of the IEEE International Conference on Computer Vision. 2015: 3676-3684.</li><li>【5】Sun Y, Wang X, Tang X. Deep convolutional network cascade for facial point detection[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2013: 3476-3483.</li><li>【6】Zhang K, Zhang Z, Li Z, et al. Joint face detection and alignment using multitask cascaded convolutional networks[J]. IEEE Signal Processing Letters, 2016, 23(10): 1499-1503.</li></ul><h2 id="系列3：人脸表征">系列3：人脸表征</h2><h2 id="一、人脸表征"><strong>一、人脸表征</strong></h2><p>把人脸图像通过神经网络，得到一个特定维数的特征向量，该向量可以很好地表征人脸数据，使得不同人脸的两个特征向量距离尽可能大，同一张人脸的两个特征向量尽可能小，这样就可以通过特征向量来进行人脸识别。</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914141235.png" width="1093" height="254" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><h2 id="二、论文综述"><strong>二、论文综述</strong></h2><h3 id="1-DeepFace："><strong>1.</strong> <strong>DeepFace：</strong></h3><p>2014年论文DeepFace: Closing the Gap toHuman-Level Performance in Face Verification提出了DeepFace算法，第一个真正将<a target="_blank" rel="noopener external nofollow noreferrer" href="https://cloud.tencent.com/solution/bigdata?from=10680">大数据</a>和深度学习神经网络结合应用于人脸识别与验证。在该人脸识别模型中分为四个阶段：人脸检测 =&gt; 人脸对齐 =&gt; 人脸表征 =&gt; 人脸分类，在LFW数据集中可以达到97.00%的准确率。</p><p>（1）人脸检测与对齐：该模型使用3D模型来将人脸对齐，该方法过于繁琐，在实际应用中很少使用，经过3D对齐以后，形成的图像都是152×152的图像，具体步骤如下图。</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-1.png" width="1046" height="684" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>分为如下几步：</p><p>a. 人脸检测，使用6个基点 b. 二维剪切，将人脸部分裁剪出来 c. 67个基点，然后Delaunay三角化，在轮廓处添加三角形来避免不连续 d. 将三角化后的人脸转换成3D形状 e. 三角化后的人脸变为有深度的3D三角网 f. 将三角网做偏转，使人脸的正面朝前。 g. 最后放正的人脸 h. 一个新角度的人脸（在论文中没有用到）</p><p>（2）人脸表征：人脸表征使用了5个卷积层和1个最大池化层、1个全连接层，如下图所示。前三层的目的在于提取低层次的特征,为了网络保留更多图像信息只使用了一层池化层；后面三层都是使用参数不共享的卷积核，因为主要是因为人脸不同的区域的特征是不一样的，具有很大的区分性，比如鼻子和眼睛所表示的特征是不一样的，但是使用参数不共享的卷积核也增加了模型计算量以及需要更多的训练数据。最后输出的4096维向量进行L2归一化。</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914141316.png" width="1100" height="272" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>a. Conv：32个11×11×3的卷积核</p><p>b. max-pooling: 3×3， stride=2</p><p>c. Conv: 16个9×9的卷积核</p><p>d. Local-Conv: 16个9×9的卷积核，Local的意思是卷积核的参数不共享</p><p>e. Local-Conv: 16个7×7的卷积核，参数不共享</p><p>f. Local-Conv: 16个5×5的卷积核，参数不共享</p><p>g. Fully-connected: 4096维</p><p>h. Softmax: 4030维</p><p>（3）分类：论文介绍了两种方法进行分类，加权的卡方距离和使用Siamese网络结构，设f1和f2为特征向量，上一个步骤的输出，则有：</p><p>①加权卡方距离：计算公式如下，加权参数由线性SVM计算得到：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-2.png" width="634" height="62" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>②Siamese网络：网络结构是成对进行训练，得到的特征表示再使用如下公式进行计算距离：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-3.png" width="437" height="56" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><h3 id="2-DeepID1："><strong>2.</strong> <strong>DeepID1：</strong></h3><p>DeepID1 是2014年Deep LearningFace Representation from Predicting 10,000 Classes一文提出的，是DeepID三部曲的第一篇。DeepID1 使用softmax多分类训练，主要思想第一个是数据集的增大，包括训练集使用celebface，包含87628张图片，5436个人脸，增大了训练集；使用多尺寸输入，通过5个landmarks将每张人脸划分成10regions，每张图片提取60patches=10regions<em>3scales</em>2(RGB orgray)，第二个是网络结构，DeepID提取的人脸特征就是一个由连接第三层与第四层组成的全连接层特征，如下图所示，每个patches经过这个cnn网络，第四层的特征更加全局化（global），第三层的特征更加细节，因此DeepID连接了两者，以求同时包含全局，细节信息。</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-4.png" width="1103" height="488" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>60个patches使用60个CNN,每个CNN提取2*160=320维特征（与水平翻转一起输入），总网络模型如下图所示，最后分别使用联合贝叶斯算法与神经网络进行分类，并比较结果。</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-5.png" width="941" height="600" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>模型最终以CelebFaces+中202,599图像作为训练集， patch数提升为100（10r<em>10s</em>2） ，特征数提升为100<em>160</em>2=32000 然后使用PCA降为150维 ，使用联合贝叶斯算法进行验证， 最终在LFW上达到97.20%的验证准确率。</p><h3 id="3-DeepID2："><strong>3.</strong> <strong>DeepID2：</strong></h3><p>DeepID2是Deep Learning Face Representationby Joint Identification-Verification一文提出的，对DeepID1进行了进一步的改进，提出了contrastive loss，在分类任务，我们需要的是减少类内差距（同一人脸），增加类间差距（不同人脸），softmax loss分类的监督信号可以增大类间差距，但是却对类内差距影响不大，所以DeepID2加入了另一个loss，contrastive loss，从而增加验证的监督信号，就可以减少类内差距。</p><p>网络结构类似DeepID1,不同之处在于使用了两种不同的损失函数，网络结构如下图所示。</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-6.png" width="1103" height="346" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>损失函数：</p><p>①分类信号，Softmax loss。</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-7.png" width="811" height="165" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>②验证信号，contrastiveloss，使用l2范数距离表示，m为阈值不参与训练，括号内的θve={m}，该损失函数可以让类间的距离给定一个限制margin，即m大小的距离。</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-8.png" width="1086" height="168" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-9.png" width="787" height="154" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>两loss的组合方式： 首先使用2个输入，计算Softmax loss和contrastive loss,总损失为二者通过λ加权求和，通过总损失来执行梯度下降更新卷积参数，通过Softmax loss来更新softmax层的参数。</p><p>整个模型使用celebrate+数据集训练，每张图片使用了21 facial landmarks，分成200patches（20regions<em>5scales</em>2RGB&amp;Gray)，水平翻转后变为400patches，使用了200个卷积神经网络，提取400（200<em>2）个Deepid2特征，使用贪婪算法降为25个Deepid2特征，使用PCA将25</em>160Deepid2特征降为180维，最后使用联合贝叶斯算法进行验证，最终在LFW上得到的最终准确率是98.97%，使用7组25个Deepid2特征，SVM融合可得到准确率为99.15% 。DeepID2在2014 年是人脸领域非常有影响力的工作，也掀起了在人脸领域引进 MetricLearning 的浪潮。</p><h3 id="4-DeepID2-："><strong>4.</strong> <strong>DeepID2+：</strong></h3><p>DeepID2+源于论文Deeply learned facerepresentations are sparse, selective, and robust，DeepID2+是对DeepID2的改进。①卷积层在原来基础上再增加128维，第四层全连接层从160增加到512，训练数据增加了CelebFaces+ dataset，WDRef等，有12000个人脸的大约290,000张图片； ②每个卷积层的后面都加了一个512为的全连接层，并添加contrastive loss监督信号，而不仅在第四层全连接层上有 。网络结构如下图所示。</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-10.png" width="1005" height="990" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>最终在LFW数据集上准确率为99.47%。</p><h3 id="5-DeepID3："><strong>5.</strong> <strong>DeepID3：</strong></h3><p>DeepID3源于2015年的Deepid3:Face recognition with very deep neural networks论文，该论文探究了复杂神经网络对人脸识别的作用。论文研究VGG与GoogleNet用于人脸识别的效果，论文在VGG和GooLeNet的基础上进行构建合适的结构，使得方便人脸识别。结果发现DeepID3的结果和DeepID2+相当，可能是由于数据集的瓶颈，需要更大的数据才能有更好的提升，两个网络结构如下图所示。</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-11.png" width="1089" height="867" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>网络输出使用PCA降维到300维的向量，使用联合贝叶斯算法进行验证，最终在LFW上得到的最终准确率是99.53%。</p><h3 id="6-FaceNet："><strong>6.</strong> <strong>FaceNet：</strong></h3><p>FaceNet由论文Facenet: A unified embedding forface recognition and clustering提出，这篇 2015 年来自 Google 的 论文同样具有非常大的影响力，不仅仅成功应用了 TripletLoss 在 benchmark 上取得state-of-art 的结果，更因为他们提出了一个绝大部分人脸问题的统一解决框架，即：识别、验证、搜索等问题都可以放到特征空间里做，需要专注解决的仅仅是如何将人脸更好的映射到特征空间。FaceNet在DeepID的基础上，将 ContrastiveLoss 改进为 Triplet Loss，去掉softmaxloss。FaceNet实验了ZFNet类型网络和Inception类型网络，最终Inception类型网络效果更好，网络结构如下图所示。</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-12.png" width="1097" height="516" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>FaceNet没有使用PCA降维，而是在网络中直接训练输出128维的向量，用全连接层来完成降维，最后的128维的向量经过Triplet Loss。</p><p>Triplet Loss输入不再是 Image Pair，而是三张图片（Triplet），分别为 Anchor Face（xa），Negative Face（xn）和 Positive Face（xp）。Anchor 与 Positive Face 为同一人，与 Negative Face 为不同人，在特征空间里 Anchor 与 Positive 的距离要小于 Anchor 与 Negative 的距离，且相差超过一个 Margin Alpha。</p><p>loss的目标为：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-13.png" width="567" height="66" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>总loss公式为：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-14.png" width="665" height="122" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>Contrastive Loss与Triplet Loss的比较， Contrastive Loss目标是减少类内差距（两个蓝点），增加类间差距（蓝点与红点）；Triplet Loss则是输入三张图片，Anchor 与 Positive 的距离要小于 Anchor 与 Negative 的距离，且相差超过一个 Margin Alpha，即Triplet Loss同时约束了两个距离。</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-15.png" width="1109" height="369" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>最后FaceNet在LFW数据集上达到了99.63%的准确率。</p><p>基于 ContrastiveLoss 和 Triplet Loss 的 MetricLearning 符合人的认知规律，在实际应用中也取得了不错的效果，但同时也有很多问题，由于ContrastiveLoss 和 Triplet Loss 的训练样本都基于pair 或者 triplet 的，可能的样本数是 O(N2) 或者 O (N3) 的，所以模型需要很久的计算才能拟合并且训练集需要足够大。</p><h2 id="三、总结"><strong>三、总结</strong></h2><p>本期文章主要介绍人脸表征相关算法和论文综述，主要是2014年到2016年的研究成果， ContrastiveLoss 和 Triplet Loss在实际应用中也取得了很好的效果，但是也有很多问题，由于Contrastive Loss 和 Triplet Loss 的训练样本都基于 pair 或者 triplet 的，可能的样本数是 O (N2) 或者 O (N3) 的，所以模型需要很久的计算才能拟合并且训练集要足够大，所以在之后的人脸识别研究中，大部分在于loss函数的研究，这部分将会在下一期给大家介绍。</p><h3 id="参考文献：-2"><strong>参考文献：</strong></h3><ul><li>【1】 Taigman Y, Yang M, Ranzato M A, et al.Deepface: Closing the gap to human-level performance in faceverification[C]//Proceedings of the IEEE conference on computer vision andpattern recognition. 2014: 1701-1708.</li><li>【2】Sun Y, Wang X, Tang X. Deep learning facerepresentation from predicting 10,000 classes[C]//Proceedings of the IEEEconference on computer vision and pattern recognition. 2014: 1891-1898.</li><li>【3】Sun Y, Chen Y, Wang X, et al. Deeplearning face representation by joint identification-verification[C]//Advancesin neural information processing systems. 2014: 1988-1996.</li><li>【4】Sun Y, Liang D, Wang X, et al. Deepid3:Face recognition with very deep neural networks[J]. arXiv preprintarXiv:1502.00873, 2015.</li><li>【5】Simonyan K, Zisserman A. Very deepconvolutional networks for large-scale image recognition[J]. arXiv preprintarXiv:1409.1556, 2014.</li><li>【6】Szegedy C, Liu W, Jia Y, et al. Goingdeeper with convolutions[C]//Proceedings of the IEEE conference on computervision and pattern recognition. 2015: 1-9.</li><li>【7】Sun Y, Wang X, Tang X. Deeply learned facerepresentations are sparse, selective, and robust[C]//Proceedings of the IEEEconference on computer vision and pattern recognition. 2015: 2892-2900.</li><li>【8】Schroff F, Kalenichenko D, Philbin J.Facenet: A unified embedding for face recognition andclustering[C]//Proceedings of the IEEE conference on computer vision andpattern recognition. 2015: 815-823.</li></ul><h2 id="系列4：人脸表征-续">系列4：人脸表征-续</h2><h2 id="一、人脸表征-2"><strong>一、人脸表征</strong></h2><p>把人脸图像通过神经网络，得到一个特定维数的特征向量，该向量可以很好地表征人脸数据，使得不同人脸的两个特征向量距离尽可能大，同一张人脸的两个特征向量尽可能小，这样就可以通过特征向量来进行人脸识别。</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-16.png" width="1106" height="275" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><h2 id="二、论文综述-2"><strong>二、论文综述</strong></h2><h3 id="1-L-Softmax："><strong>1.</strong> <strong>L-Softmax：</strong></h3><p>Softmax Loss函数被广泛应用于深度学习，较为简单实用，但是它并不能够明确引导神经网络学习区分性较高的特征。L-Softmax能够有效地引导网络学习使得样本类内距离较小、类间距离较大的特征，L-Softmax不但能够调节类间距离的间隔（margin）大小，而且能够防止过拟合。</p><p>L-Softmax是对softmax loss的改进，softmax loss公式如下所示：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-17.png" width="520" height="110" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>其中 fj 表示最终全连接层的类别输出向量 f的第 j个元素, N为训练样本的个数，则 fyi可以表示为 fyi=WTyi xi，其中 0≤θj≤π，最终的损失函数可得：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-18.png" width="437" height="126" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>softmax的目的是使得WT1x&gt;WT2x，即 ∥W1∥∥x∥cos(θ1)&gt;∥W2∥∥x∥cos(θ2)，从而得到输入x（来自类别1）输出正确的分类结果。L-Softmax通过增加一个正整数变量m，从而产生一个决策余量，能够更加严格地约束上述不等式，即：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-19.png" width="513" height="105" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>其中0≤θ1&lt;π/m。如果W1和W2能够满足∥W1∥∥x∥cos(mθ1)&gt;∥W2∥∥x∥cos(θ2)，那么就必然满足∥W1∥∥x∥cos(θ1)&gt;∥W2∥∥x∥cos(θ2)，这样的约束对学习W1和W2的过程提出了更高的要求，在训练学习过程中，类间要比之前多了一个m的间隔，从而使得1类和2类有了更宽的分类决策边界。这种Margin Based Classification使得学习更加的困难，从而使类间距离增加了一个margin距离，L-Softmax loss的总公式如下：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-20.png" width="734" height="282" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>当m越大时，分类的边界越大，学习难度当然就越高。</p><p>论文仅使用了WebFace数据集作为训练集和一个简单的卷积网络，就在LFW上达到了98.71%的正确率，证明了L-Softmax loss取得了比softmax loss更好的结果。</p><h3 id="2-SphereFace"><strong>2.</strong> <strong>SphereFace :</strong></h3><p>SphereFace在MegaFace数据集上识别率在2017年排名第一，提出A-Softmax Loss使人脸识别达到不错的效果。A-Softmax Loss基于softmax loss和L-Softmax loss，在二分类模型中，softmax loss为：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-21.png" width="577" height="168" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>如果x为类别一，则希望p1&gt;p2,则二分类的划分函数为：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-22.png" width="410" height="69" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>权重归一化||w||为1，b为0，此时特征上的点映射到单位超球面上，则二分类的划分函数为：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-23.png" width="320" height="54" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>然后使用与L-Softmax loss相同的原理，使</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-24.png" width="292" height="53" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>则A-Softmax Loss最终为：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-25.png" width="835" height="144" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>因此A-Softmax Loss是样本类别之间产生了角度距离，让决策函数更加严格并且更加具有可区分性。当m增大，角度距离也会增加。</p><p>A-Softmax与L-Softmax的最大区别在于A-Softmax的权重归一化了，而L-Softmax则没有。A-Softmax权重的归一化导致特征上的点映射到单位超球面上，A-Softmax仅仅能从角度上划分类别，而L-Softmax是在角度与长度方向进行考量，两个方向如果划分不一就会收到干扰，导致精度下降。</p><p>SphereFace使用的模型如下图所示：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-26.png" width="1111" height="456" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>训练与测试过程如下图所示，在测试过程中使用余弦计算相似度：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-27.png" width="820" height="261" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>最终SphereFace在训练集较小的情况下，LFW数据集上准确率为99.42%。Sphereface效果很好，但是它不优美。在测试阶段，Sphereface通过特征间的余弦值来衡量相似性，即以角度为相似性的度量，在训练阶段，其实Sphereface的损失函数并不是在直接优化特征与类中心的角度，而是优化特征与类中心的角度在乘上一个特征的长度，这就造成了训练跟测试之间目标不一致。</p><h3 id="3-Normface"><strong>3.</strong> <strong>Normface :</strong></h3><p>在优化人脸识别任务时，softmax本身优化的是没有归一化的内积结果，但是最后在预测的时候使用的一般是cosine距离或者欧式距离，这会导致优化目标和最终的距离度量其实并不一致。 Normface的核心思想是既然最后在特征对比的时候使用归一化的cosine距离，那么在训练的过程中把特征也做归一化处理，做了归一化之后，softmax的优化就变成了直接优化cosine距离了，归一化过程如下，其中e是为了防止除0的较小正数：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-28.png" width="305" height="105" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>相应的损失函数如下：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-29.png" width="470" height="130" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>其中 W 是归一化的权重，f_i 是归一化的特征，参数 s 的引入是因为保证梯度大小的合理性，去掉bias是因为softmax之前的fc有bias的情况下会使得有些类别在角度上没有区分性但是通过bias可以区分，在这种情况下如果对feature做normalize，会使得中间的那个小类别的feature变成一个单位球形并与其他的feature重叠在一起，所以在feature normalize的时候是不能加bias的。</p><p>Normface使用了较小的模型使用多种loss训练，然后在LFW数据集上测试，证明了feature normalize的效果，结果如下：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142413.png" width="1106" height="673" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><h3 id="4-CosFace"><strong>4.</strong> <strong>CosFace :</strong></h3><p>Normface用特征归一化解决了Sphereface训练和测试不一致的问题。但是却没有了margin的惩罚，腾讯AI Lab的CosFace或者AM-softmax是在Normface的基础上引入了margin，损失函数为：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-30.png" width="751" height="135" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>其中特征与权值都做了归一化：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-31.png" width="413" height="259" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>分类决策为：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-32.png" width="317" height="51" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>，比之前增加了m的margin，m 是一个超参数，控制惩罚的力度，m 越大，惩罚越强。</p><p>CosFace使用mtcnn进行人脸检测与对齐，人脸表征训练模型使用基于residual units 64层卷积网络的Sphere Face，在5M的训练集上训练，在LFW数据集上测试，精度达到99.73%。</p><h3 id="5-ArcFace"><strong>5.</strong> <strong>ArcFace :</strong></h3><p>ArcFace源于论文Additive angular margin lossfor deep face recognition，也叫做InsightFace，论文基本介绍了近期较为流行的人脸识别模型，loss变化从softmax到AM-softmax，然后提出ArcFace，可以说起到了很好的综述作用，论文从三个方面探讨影响人脸识别模型精度的主要因素。</p><p>（1）数据：数据方面，论文探讨了各个数据集的数据质量和优缺点，并对MS-Celeb-1M，MegaFace FaceScrub做了清洗，清洗后的数据公开。</p><p>（2）网络：详细对比了不同的主流网络结构的性能，包括输入层尺寸大小、最后输出几层的不同结构、基本网络单元残差网络的不同结构、主干网络的不同模型。经过实验的证明，最后的网络结构：输入图片大小112x112；第一层convLayer 卷积核为3<em>3 stride 1时，网络输出7</em>7；主干网络使用ResNet100，并使用改进后的改进的残差网络结构，如下图；最后的几层输出层为最后一个卷积层后+BN-Dropout-FC-BN的结构。</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-33.png" width="398" height="455" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>（3）损失函数：与 AM-softmax相比，区别在于Arcface引入margin的方式不同，损失函数为：</p><p><img src="https://cimg1.17lai.site/data/2021/09/1420210914142652-34.png" width="1017" height="198" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt=""></p><p>Arcface的m是在余弦里面，AM-softmax的在外面，ArcFace更为直观并且在超球面维度上有更清晰的解释。Arcface在VGG2和MS-Celeb-1M数据集上训练，在LFW数据集上精度达到99.83%。</p><h2 id="三、总结-2"><strong>三、总结</strong></h2><p>本期文章主要介绍人脸表征相关算法和论文综述，人脸检测、对齐、特征提取等这些操作都可以在静态数据中完成，下一期将给大家介绍在视频数据中进行人脸识别的另一个重要的算法，视频人脸跟踪的概念与方法。</p><h3 id="参考文献：-3"><strong>参考文献：</strong></h3><ul><li>【1】 Liu W, Wen Y, Yu Z, et al. Large-MarginSoftmax Loss for Convolutional Neural Networks[C]//ICML. 2016: 507-516.1708.</li><li>【2】Liu W, Wen Y, Yu Z, et al. Sphereface:Deep hypersphere embedding for face recognition[C]//The IEEE Conference onComputer Vision and Pattern Recognition (CVPR). 2017, 1: 1.</li><li>【3】Wang F, Xiang X, Cheng J, et al. Normface:l 2 hypersphere embedding for face verification[C]//Proceedings of the 2017 ACMon Multimedia Conference. ACM, 2017: 1041-1049.</li><li>【4】Wang F, Cheng J, Liu W, et al. Additivemargin softmax for face verification[J]. IEEE Signal Processing Letters, 2018,25(7): 926-930.</li><li>【5】Wang H, Wang Y, Zhou Z, et al. CosFace:Large margin cosine loss for deep face recognition[J]. arXiv preprintarXiv:1801.09414, 2018.</li><li>【6】Deng J, Guo J, Zafeiriou S. Arcface:Additive angular margin loss for deep face recognition[J]. arXiv preprintarXiv:1801.07698, 2018.</li></ul><p>编辑整理 <a target="_blank" rel="noopener external nofollow noreferrer" href="https://cloud.tencent.com/developer/article/1160037?from=article.detail.1344438">磐创AI技术团队</a></p><h2 id="系列教程"><strong>系列教程</strong></h2><p><a href="/atom.xml"><i class="fas fa-rss"></i>全部文章RSS订阅</a></p><h3 id="AI系列"><strong>AI系列</strong></h3><p><a href="/categories/ai/atom.xml"><i class="fas fa-rss"></i><strong>AI 分类 RSS 订阅</strong></a></p><ul><li><a href="/posts/a0f3c838/">深度学习之视频人脸识别系列</a></li><li><a href="/posts/1336c869/">中国区注册ChatGPT并使用全流程图解教程</a></li><li><a href="/posts/60146716/">关于普朗克概率的的讨论</a></li><li><a href="/posts/b648bb9c/">信用卡对个人、社会以及国家的影响——ChatGPT辅助编写</a></li></ul><h3 id="Hexo系列"><strong>Hexo系列</strong></h3><p><a href="/categories/hexo/atom.xml"><i class="fas fa-rss"></i><strong>HexoRSS分类订阅</strong></a></p><p>[三万字教程]基于Hexo的matery主题搭建博客并深度优化完全一站式教程</p><ul><li><a href="/posts/40300608/">Hexo Docker环境与Hexo基础配置篇</a></li><li><a href="/posts/4d8a0b22/">hexo博客自定义修改篇</a></li><li><a href="/posts/9b056c86/">hexo博客网络优化篇</a></li><li><a href="/posts/5311b619/">hexo博客增强部署篇</a></li><li><a href="/posts/4a2050e2/">hexo博客个性定制篇</a></li><li><a href="/posts/84b4059a/">hexo博客常见问题篇</a></li><li><a href="/posts/253706ff/">hexo博客博文撰写篇之完美笔记大攻略终极完全版</a></li><li><a href="/posts/cf0f47fd/">Hexo Markdown以及各种插件功能测试</a></li></ul><blockquote><ul><li>markdown 各种其它语法插件，latex公式支持，mermaid图表，plant uml图表，URL卡片，bilibili卡片，github卡片，豆瓣卡片，插入音乐和视频，插入脑图，插入PDF，嵌入iframe</li></ul></blockquote><ul><li><a href="/posts/217ccdc1/">在 Hexo 博客中插入 ECharts 动态图表</a></li><li><a href="/posts/546887ac/">使用nodeppt给hexo博客嵌入PPT演示</a></li><li><a href="/posts/a3c81cc3/">GithubProfile美化与自动获取RSS文章教程</a></li><li><a href="/posts/e922fac8/">Vercel部署高级用法教程</a></li><li><a href="/posts/eb731135/">webhook部署Hexo静态博客指南</a></li><li><a href="/posts/8f9792ab/">在宝塔VPS上面采用docker部署waline全流程图解教程</a></li><li><a href="/posts/843eb2k9/">自建Umami访问统计服务并统计静态博客UV/PV</a></li></ul><h3 id="Docker系列"><strong>Docker系列</strong></h3><p><a href="/categories/docker/atom.xml"><i class="fas fa-rss"></i><strong>Docker 分类 RSS 订阅</strong></a></p><ul><li><a href="/posts/42b6a86d/">Docker使用简明教程</a></li><li><a href="/posts/9912bd5d/">使用jeckett,sonarr,iyuu,qt,emby打造全自动追剧流程</a></li><li><a href="/posts/1802a8a7/">为知笔记私有化Docker部署</a></li><li><a href="/posts/593cc323/">Earthly 一个更加强大的镜像构建工具</a></li><li><a href="/posts/90e60aac/">使用 Shell 脚本实现一个简单 Docker</a></li><li><a href="/posts/465d2738/">如何使用Traefik V2 在Ubuntu20.04 上面来做 Dockers</a></li><li><a href="/posts/462f1e5c/">通过IPV6访问Qnap NAS中Docker的服务</a></li></ul></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">作者: </i></span><span class="reprint-info"><a href="https://blog.17lai.site" rel="external nofollow noreferrer">夜法之书</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://blog.17lai.site/posts/a0f3c838/">https://blog.17lai.site/posts/a0f3c838/</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://blog.17lai.site" target="_blank">夜法之书</a> !</span></div></div><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/ai/"><span class="chip bg-color">ai</span> </a><a href="/tags/face/"><span class="chip bg-color">face</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><div id="article-share"><div class="social-share" data-sites="twitter,facebook,qq,qzone,wechat,weibo,douban" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div></div></div></div><div id="reward"><a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a><div id="rewardModal" class="modal"><div class="modal-content"><a class="close modal-close" href="javascript:;" rel="external nofollow noreferrer" aria-label="打赏作者"><i class="fa fa-times-circle"></i></a><p class="reward-title">码字辛苦，打赏作者！</p><div class="reward-content"><div class="reward-tabs"><ul class="tabs row"><li class="tab col s6 alipay-tab"><a href="#alipay">支付宝</a></li><li class="tab col s6 wechat-tab"><a href="#wechat">微 信</a></li></ul><div id="alipay"><img src="/medias_webp/reward/alipay.webp" width="511" height="511" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload loading="lazy" class="reward-img" alt="支付宝打赏二维码"></div><div id="wechat"><img src="/medias_webp/reward/wechat.webp" width="595" height="580" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload loading="lazy" class="reward-img" alt="微信打赏二维码"></div></div></div></div></div></div><div class="webpush-dingyue" style="margin:10px 0;text-align:center"><div id="webpushr-subscription-button" data-size="small" data-button-text="订阅博文" data-subscriber-count-text="个用户已订阅" data-background-color="#6295d0"></div></div></div></div><div id="comments" lazyload><div class="card waline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div class="center hvcenter" id="loading_data"><i class="fas fa-spinner fa-pulse"></i> <span>数据加载中 ...</span></div><div id="waline" class="card-content" style="display:grid"></div></div><div id="to_comment" data-umami-event-commentbtn="comment btn click" class="comment-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="javascript:;" rel="external nofollow noreferrer" title="直达评论"><i class="fas fa-comments"></i></a></div></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/647e6265/"><div class="card-image card-image-V"><div class="box-content"><p class="title">阅读全文</p><span class="post" style="width:180px">Vim IDE Docker 以及中文指南</span></div><img src="/medias_webp/cover/vim.webp" width="1183" height="660" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload class="responsive-img" alt="Vim IDE Docker 以及中文指南"> <span class="card-title title-V">Vim IDE Docker 以及中文指南</span></div></a><div class="card-content article-content"><div class="summary block-with-text">Vim dockers 推荐。Vim 中文指南。快捷键详细介绍，以及附赠一个Vim Checklist图。在网页上端导航栏，[快查] => [更多快查表]，有更多快查表！</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2021-09-15 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/tools/" class="post-category">tools</a></span></div></div><div class="card-action article-tags"><a href="/tags/linux/"><span class="chip bg-color">linux</span> </a><a href="/tags/docker/"><span class="chip bg-color">docker</span> </a><a href="/tags/vim/"><span class="chip bg-color">vim</span> </a><a href="/tags/ide/"><span class="chip bg-color">ide</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/509c7bd3/"><div class="card-image card-image-V"><div class="box-content"><p class="title">阅读全文</p><span class="post" style="width:180px">自动曝光原理</span></div><img src="/medias_webp/cover/imgprogress.webp" width="913" height="409" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload class="responsive-img" alt="自动曝光原理"> <span class="card-title title-V">自动曝光原理</span></div></a><div class="card-content article-content"><div class="summary block-with-text">自动曝光原理简单介绍，以及其简单实现方法原理。自动曝光就是相机代替人的操作，自动调节曝光时间、光圈、ISO进行曝光，使得所摄物体亮度正常。这句话解释起来很简单，但是存在两个难点问题：第一，相机不如人眼这样可以直观的分辨图像明暗，如何判断这幅图像是否亮度合适；第二，如何调整曝光时间、光圈、ISO,这三者调节的比例。</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2021-09-14 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/embeded/" class="post-category">embeded</a></span></div></div><div class="card-action article-tags"><a href="/tags/3a/"><span class="chip bg-color">3a</span> </a><a href="/tags/ae/"><span class="chip bg-color">ae</span> </a><a href="/tags/image/"><span class="chip bg-color">image</span></a></div></div></div></div></article></div></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div id="aside-container" style="display:flex;flex-direction:column"><div class="toc-widget card"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div><div class="tgCard card"><div class="tg-container"><div class="tg-Card col-12" style="background-color:var(--card-bg-color)"><a href="/msg/" target="_blank" class="tg-link" data-tg-id="ad-aliHongBao"><img src="https://cimg1.17lai.site/data/2024/11/09/20241109163003.webp" width="794" height="1152" srcset="/medias_webp/loading2.svg" loading="lazy" lazyload alt="支付宝扫码领红包" class="ad-image"></a></div></div></div></div></div></div><div id="floating-toc-btn" data-umami-event-tocbtn="toc btn click" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color" href="javascript:;" rel="external nofollow noreferrer" title="显示/隐藏目录"><i class="fas fa-list-ul"></i></a></div></main><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:15px!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020-2025</span> <a href="/about" target="_blank">夜法之书</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" rel="external nofollow noreferrer" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" rel="external nofollow noreferrer" target="_blank">Matery</a> <span id="translate">|&nbsp;繁/简：</span><a id="translateLink" href="javascript:translatePage();" rel="external nofollow noreferrer">繁</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">738.7k</span> <span id="busuanzi_container_site_pv" style="display:none">&nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp; <span id="busuanzi_value_site_pv" class="white-color"></span><i id="busuanzi_loading_icon_site_pv" class="fas fa-sync fa-spin"></i> </span><span id="busuanzi_container_site_uv" style="display:none">&nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp; <span id="busuanzi_value_site_uv" class="white-color"></span><i id="busuanzi_loading_icon_site_uv" class="fas fa-sync fa-spin"></i></span><br><span id="sitetime">Loading ...</span><script>var calcSiteTime=function(){var e=new Date,t=e.getFullYear(),n=e.getMonth()+1,i=e.getDate(),a=e.getHours(),r=e.getMinutes(),s=e.getSeconds(),o=Date.UTC("2020","6","28","0","0","0"),g=Date.UTC(t,n,i,a,r,s)-o,d=Math.floor(g/31536e6),m=Math.floor(g/864e5-365*d);if("2020"===String(t)){document.getElementById("year").innerHTML=t;var l="This site has been running for "+m+" days";l="本站已运行 "+m+" 天",document.getElementById("sitetime").innerHTML=l}else{document.getElementById("year").innerHTML="2020 - "+t;var c="This site has been running for "+d+" years and "+m+" days";c="本站已运行 "+d+" 年 "+m+" 天",document.getElementById("sitetime").innerHTML=c}};calcSiteTime()</script><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/appotry" rel="external nofollow noreferrer" class="tooltipped" target="_blank" aria-label="访问我的GitHub" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github fa-fw"></i> </a><a href="https://hub.docker.com/u/bloodstar" rel="external nofollow noreferrer" class="tooltipped" target="_blank" aria-label="访问我的DockerHub" data-tooltip="访问我的DockerHub" data-position="top" data-delay="50"><i class="fab fa-docker fa-fw"></i> </a><a href="mailto:admin@17lai.fun" rel="external nofollow noreferrer" class="tooltipped" target="_blank" aria-label="邮件联系我" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open fa-fw"></i> </a><a href="/atom.xml" class="tooltipped" target="_blank" aria-label="RSS 订阅" data-tooltip="RSS 订阅" data-position="top" data-delay="50"><i class="fas fa-rss fa-fw"></i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header center"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <a class="close modal-close" href="javascript:;" rel="external nofollow noreferrer" title="关闭搜索"><span class="popup-btn-close" role="button"><i class="fas fa-times"></i></span></a></div><div class="center hvcenter" id="loading_search_data"><i class="fas fa-spinner fa-pulse"></i> <span>数据加载中 ...</span></div><div id="searchWrap" class="search-wrap" style="display:none"><div class="search-input-container"><input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div></div><div id="backTop" data-umami-event-backtop="backtop click" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#" title="回到顶部"><i class="fas fa-arrow-up"></i></a></div><script src="/js/ana.js?v=1.1.0" async></script><script type="module" async>import{commentCount}from"/libs/waline/comment.js?v=3.5.4";function upDateComment(){const e=commentCount({serverURL:"https://waline.17lai.site",path:"/posts/a0f3c838/"});setTimeout(()=>e(),3e3);try{var n="waline_comments_count",t=document.getElementById(n);t?(t.style.display="inline-block",document.getElementById("waline_commentcount_loading_icon").style.display="none",console.log("[waline] Comment count updated successfully!")):console.log("[waline] Element with id '"+n+"' not found.")}catch(e){console.log("[waline-count][Error] err")}console.log("[waline]update comment count!")}function delayUpDateComment(){setTimeout((function(){upDateComment()}),3e3),console.log("[waline]delay update comment count!")}delayUpDateComment()</script><script>$((function(){let e,n=$(".carousel"),c=!1;n.carousel({duration:Number("180"),fullWidth:!0,indicators:!0,onCycleTo(){var e;c||(e=this,setInterval(()=>{(e.pressed||e.dragged)&&r()},1e3),c=!0)}});let t=function(){e=setInterval((function(){n.carousel("next")}),8e3)};function r(){clearInterval(e),t()}t(),$("#prev-cover").click((function(){n.carousel("prev"),r()})),$("#next-cover").click((function(){n.carousel("next"),r()}))}))</script><script type="text/javascript">function handleSearchClick(){document.getElementById("searchModal");var e=document.getElementById("searchInput"),t=document.getElementById("searchResult");e.value="",t.innerHTML="",downXmlData("https://cfblog.17lai.site/search.xml").then(n=>{searchFunc(n,e,t)}).catch(e=>{console.error("Error downloading XML data:",e)})}var downXmlData=function(e){"use strict";return new Promise((t,n)=>{$.ajax({url:e,dataType:"xml",success:function(e){console.log("SUCCESS 下载玩搜索数据库文件"),document.getElementById("loading_search_data").style.display="none",document.getElementById("searchWrap").style.display="inline",document.getElementById("searchInput").focus(),t(e)},error:function(e,t,r){n(r)}})})},searchFunc=function(e,t,n){"use strict";var r=$("entry",e).map((function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}})).get();t.addEventListener("input",(function(){var e='<ul class="search-result-list">';if(n.innerHTML="",!(this.value.trim().length<=0)){var t=this.value.trim().toLowerCase().split(/[\s\-]+/),a=[];r.forEach((function(e){var n=!0,r=e.title.trim().toLowerCase(),c=e.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),l=e.url;l=0===l.indexOf("/")?e.url:"/"+l;var s=-1,i=-1,o=[];""!==r&&""!==c&&t.forEach((function(e){s=r.indexOf(e),i=c.indexOf(e),s<0&&i<0?n=!1:(i<0&&(i=0),o.push(i))})),n&&a.push({title:e.title,content:e.content,url:e.url,first_occurs:o})}));var c=a.length;a.forEach((function(n,r){var a=n.title;t.forEach((function(e){var t=new RegExp(e,"gi");a=a.replace(t,'<em class="search-keyword">'+e+"</em>")})),e+="<li><a href='"+n.url+"' class='search-result-title'>"+(r+1)+"/"+c+" "+a+"</a>";var l=n.content.trim().replace(/<[^>]+>/g,""),s=[];n.first_occurs.forEach((function(e,n){if(e>=0){var r=e-20,a=e+80;r<0&&(r=0),0===r&&(a=100),a>l.length&&(a=l.length);var c=l.substr(r,a),i=t[n],o=new RegExp(i,"gi");c=c.replace(o,'<em class="search-keyword">'+i+"</em>"),s.push('<p class="search-result">'+c+"...</p>")}})),e+=s.join(""),e+="</li>"})),e+="</ul>",n.innerHTML=e}}))}</script><script>$((function(){$(".modal-trigger").click((function(){$(".modal").modal()})),$(".tabs").tabs()}))</script><script src="/libs/materialize/materialize.min.js?v=1.2.2"></script><script src="/libs/masonry/masonry.pkgd.min.js?v=4.2.2"></script><script src="/libs/aos/aos.min.js"></script><script src="/js/events.js?v=1.0.0"></script><script src="/js/plugins.js?v=1.0.1"></script><script>window.githubCardsLoader={config:{phases:[{time:2e3,text:"Fetching profile data..."},{time:5e3,text:"Finalizing display..."}],maxRetries:2},init:function(e=0){const t=document.querySelectorAll(".github-card-container");if(!t.length)return;if(this.cleanup(),t.forEach(e=>{this.createLoader(e),this.startPhaseMonitor(e)}),document.getElementById("github-cards-script"))return;const n=document.createElement("script");n.id="github-cards-script",n.src="/libs/githubCards/jsdelivr/widget.min.js",n.async=!0,n.onload=()=>{console.log("[GitHub Cards] 渲染引擎加载成功"),this.handleSuccess()},n.onerror=()=>{console.warn("[GitHub Cards] 渲染引擎加载失败"),this.handleError(e)},document.head.appendChild(n)},createLoader:function(e){const t=document.createElement("div");t.className="github-card-loader";const n=document.createElement("div");n.className="github-card-spinner";const i=document.createElement("span");i.className="github-card-loading-text",i.textContent="Initializing GitHub card...",t.appendChild(n),t.appendChild(i),e.style.position="relative",e.style.minHeight="150px",e.appendChild(t)},startPhaseMonitor:function(e){const t=e.querySelector(".github-card-loading-text");this.config.phases.forEach(e=>{setTimeout(()=>{t&&(t.textContent=e.text)},e.time)})},handleSuccess:function(){document.querySelectorAll(".github-card-loader").forEach(e=>{e.parentNode.removeChild(e)})},handleError:function(e){document.querySelectorAll(".github-card-container").forEach(t=>{const n=document.createElement("div");n.className="github-card-error";const i=document.createElement("span");i.textContent="Content load failed"+(e>0?` (${e}/${this.config.maxRetries})`:"");const r=document.createElement("button");r.className="github-card-retry",r.textContent="Retry",r.onclick=()=>{e<this.config.maxRetries&&this.init(e+1)},n.appendChild(i),n.appendChild(r),t.parentNode.replaceChild(n,t)})},cleanup:function(){document.querySelectorAll(".github-card-error").forEach(e=>{e.parentNode.removeChild(e)})}},document.addEventListener("DOMContentLoaded",()=>window.githubCardsLoader.init()),document.addEventListener("pjax:complete",()=>window.githubCardsLoader.init())</script><script src="/libs/typed/typed.umd.js?v=2.1.0"></script><script>document.querySelector("#typed-strings")&&document.querySelector("#typed")&&windowWidth>minFunWidth&&new Typed("#typed",{stringsElement:"#typed-strings",startDelay:50,typeSpeed:70,loop:!1,backSpeed:50,showCursor:!0,cursorChar:"_"})</script><script>document.querySelector("#subtitle")&&document.querySelector("#subtitle-strings")&&windowWidth>minFunWidth&&new Typed("#subtitle",{stringsElement:"#subtitle-strings",startDelay:100,typeSpeed:80,loop:!0,backSpeed:50,showCursor:!0})</script><script type="text/javascript">inPageScroll()</script><script>var tocSchemaStorageKey=window.location.pathname.replace(/\/$/,"")+"/toc";function setLS(t,e){try{localStorage.setItem(t,e)}catch(t){}}function getLS(t){try{return localStorage.getItem(t)}catch(t){return null}}getLS(tocSchemaStorageKey)||setLS(tocSchemaStorageKey,"show")</script><script src="/libs/tocbot/tocbot.min.js?v=4.35.0"></script><script>$((function(){if(windowWidth<800)return!0;document.documentElement;var e=jQuery("#toc-aside .toc-widget");if(0===e.length||!window.tocbot)return;var t=jQuery("#headNav").height()+10,o=window.location.pathname.replace(/\/$/,"")+"/toc",s=getLS(o);let n=$("#toc-aside"),l=$("#main-content");function i(e){return"show"===s?(console.log("Current page toc: show"),!0):"hide"===s?(console.log("Current page toc: hide"),!1):void console.log("Current page toc: unknow, use default")}var a=e[0].getElementsByClassName("is-active-li");e[0].getElementsByClassName("toc-title");function c(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-t,scrollSmoothOffset:-t,collapseDepth:Number("0"),scrollSmooth:!0,headingSelector:"h1,h2,h3,h4,h5,h6"}),e.find(".toc-list-item").length>0&&e.css("visibility","visible")}window.onscroll=()=>{e.length>0&&(a.length>0&&a[0].offsetTop>e[0].offsetHeight&&(e[0].scrollTop=a[0].offsetTop-e[0].offsetHeight/2),a.length>0&&e[0].offsetHeight>a[0].offsetHeight&&(e[0].scrollTop=0),a.length>0&&a[0].offsetTop>e[0].offsetHeight&&(e[0].scrollTop=a[0].offsetTop-e[0].offsetHeight/2))},getLS(o),("show"===s?(console.log("Current page toc: show"),n.addClass("expanded").show(),l.addClass("l9"),1):"hide"===s?(console.log("Current page toc: hide"),n.removeClass("expanded").hide(),l.removeClass("l9"),0):void console.log("Current page toc: unknow, use default"))&&c();let d=parseInt(.75*$(window).height()-64),r=$("#aside-container");$(window).scroll((function(){$(window).scrollTop()>d?r.addClass("toc-fixed"):r.removeClass("toc-fixed")})),fixPostCardWidth("artDetail","prenext-posts"),$("#floating-toc-btn .btn-floating").click((function(){n.hasClass("expanded")?(n.removeClass("expanded").hide(),l.removeClass("l9"),i(getLS(o))||tocbot.destroy(),setLS(o,"hide")):(i(getLS(o))||c(),setLS(o,"show"),n.addClass("expanded").show(),l.addClass("l9")),fixPostCardWidth("artDetail","prenext-posts"),AOS.refresh(),progressBarInit()}))}))</script><script>$("#articleContent").on("copy",(function(e){if(void 0!==window.getSelection){var n=window.getSelection();if(!((""+n).length<Number.parseInt("120"))){var t=document.getElementsByTagName("body")[0],o=document.createElement("div");o.style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"PRE"!==n.getRangeAt(0).commonAncestorContainer.nodeName&&"CODE"!==n.getRangeAt(0).commonAncestorContainer.nodeName||(o.innerHTML="<pre>"+o.innerHTML+"</pre>");var i=document.location.href;o.innerHTML+='<br />来源: 夜法之书<br />作者: 夜法之书<br />文章链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout((function(){t.removeChild(o)}),200)}}}))</script><script>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",(function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})}))</script><script type="text/javascript" async>const RetryManager={maxAttempts:3,delayBase:1e3,track:new WeakMap,handleRetry(t){const e=this.track.get(t)||0;e>=this.maxAttempts||(this.track.set(t,e+1),setTimeout(()=>{t.src=t.src},this.delayBase*Math.pow(2,e)))}};function setupLazyLoad(t){Matery.utils.waitElementVisible(t,()=>{t.hasAttribute("data-lazy-src")?handleBgWithLazySrc(t):t.hasAttribute("bg-lazy")?handleBgLazy(t):"IMG"===t.tagName&&handleImageLoad(t)},CONFIG.lazyload.offset_factor)}function handleBgWithLazySrc(t){const e=t.dataset.lazySrc;t.removeAttribute("data-lazy-src"),t.classList.add("preload");const a=new Image;a.onload=()=>{t.classList.replace("preload","loaded"),t.style.backgroundImage=`url(${e})`,t.removeAttribute("bg-lazy")},a.onerror=()=>RetryManager.handleRetry(a),a.src=e}function handleBgLazy(t){t.removeAttribute("bg-lazy")}function handleImageLoad(t){t.setAttribute("srcset",t.getAttribute("src")),t.removeAttribute("srcset"),t.removeAttribute("lazyload"),t.classList.add("preload"),t.onload=function(){t.classList.replace("preload","loaded"),t.removeAttribute("failed"),throttledFreshAOS(),removeRetryButton(t)},t.onerror=function(){t.hasAttribute("failed")||(t.setAttribute("failed",""),createRetryButton(t),RetryManager.handleRetry(t))}}function createRetryButton(t){}function removeRetryButton(t){}document.querySelectorAll("\n      [data-lazy-src],\n      [bg-lazy],\n      img[lazyload]:not([no-lazy])\n  ").forEach(t=>setupLazyLoad(t));const throttledFreshAOS=Matery.utils.throttle(()=>AOS.refresh(),200)</script><script src="/libs/scrollprogress/scrollProgress.min.js"></script><script src="/libs/lightGallery/js/lightgallery-all.min.js" defer importance="low"></script><script type="text/javascript" src="/js/tw_cn.js?v=1.0.1"></script><script type="text/javascript">var defaultEncoding=2,translateDelay=0,cookieDomain="https://blog.17lai.site",msgToTraditionalChinese="繁",msgToSimplifiedChinese="简",translateButtonId="translateLink";translateInitilization()</script><div class="waifu"><div class="waifu-tips"></div><canvas id="live2d" class="live2d"></canvas><div class="waifu-tool"><span class="fa fa-lg fa-home"></span> <span class="fa fa-lg fa-comment"></span> <span class="fa fa-lg fa-user-circle"></span> <span class="fa fa-lg fa-street-view"></span> <span class="fa fa-lg fa-camera-retro"></span> <span class="fa fa-lg fa-info-circle"></span> <span class="fa fa-lg fa-times-circle"></span></div></div><script type="text/javascript">localStorage.getItem("viewCount")?(localStorage.viewCount=Number(localStorage.viewCount)+1,console.log("Welcome to visited again!")):(localStorage.setItem("viewCount","1"),console.log("Welcome! New Reader!"))</script><script type="text/javascript">var themeStorage=window.localStorage;window.localStorage?(console.log("设定waline count title"),themeStorage.setItem("title","夜法之书")):console.log("浏览器不支持localstorage")</script><script type="text/javascript">if(windowWidth>minFunWidth&&Number(localStorage.viewCount)>2)try{$.ajax({url:"/libs/jquery/jquery-ui.min.js?v=1.14.0",dataType:"script",cache:!0,success:function(){$.ajax({url:"/libs/live2d/waifu-tips.js",dataType:"script",cache:!0,success:function(){$.ajax({url:"/libs/live2d/live2d.js",dataType:"script",cache:!0,success:function(){live2d_settings.modelId=2,live2d_settings.modelTexturesId=17,live2d_settings.modelStorage=!0,live2d_settings.canCloseLive2d=!0,live2d_settings.canTurnToHomePage=!1,live2d_settings.waifuDraggable="axis-x",live2d_settings.waifuDraggableRevert=!0,initModel("/libs/live2d/waifu-tips.json?v=1.0.1")}})}})}})}catch(e){console.log("[Live2d][Error] JQuery is not defined.")}</script><script src="/libs/tag-common/index.js" async></script><script type="module">import{init,commentCount}from"/libs/waline/waline.min.js?v=3.5.4";const locale={lang:"zh-cn",nick:"🧊 昵称",nickError:"昵称不能少于3个字符",mail:"📧 邮箱",mailError:"请填写正确的邮件地址",link:"🔗 网址",optional:"可选",placeholder:"🤣一起来玩，留下你的足迹吧~。评论支持邮箱回复通知！📧\r\n 🚀支持注册登录，并支持weibo QQ Github 社交登录(⊙o⊙)！💖\r\n 💣请文明评论哦禁止恶意评论🈲\r\n ⚠️公开网络空间，请不要发表任何包含个人或其他人的隐私信息⛔",sofa:"🌌 来发评论吧~",submit:"发送留言",like:"喜欢",cancelLike:"取消喜欢",reply:"回复",cancelReply:"取消回复",comment:"评论",refresh:"刷新",more:"加载更多评论...",preview:"预览",emoji:"表情",uploadImage:"上传图片",seconds:"秒前",minutes:"分钟前",hours:"小时前",days:"天前",now:"刚刚",uploading:"正在上传",login:"登录",logout:"退出",admin:"博主",sticky:"置顶",word:"个字",wordHint:"评论字数应在 $0 到 $1 字之间！\n当前字数：$2",anonymous:"匿名",level0:"潜水",level1:"冒泡",level2:"吐槽",level3:"活跃",level4:"话痨",level5:"传说",gif:"表情包",gifSearchPlaceholder:"搜索表情包",profile:"个人资料",approved:"通过",waiting:"待审核",spam:"垃圾",unsticky:"取消置顶",oldest:"按倒序",latest:"按正序",hottest:"按热度",reactionTitle:"雁过留声！人过留名！",reaction0:"赞一个",reaction1:"踩一下",reaction2:"有点酷",reaction3:"看不懂",reaction4:"啥玩意",reaction5:"想睡觉"};function initWaline(){console.log("[WALINE]init waline"),init({el:"#waline",locale:locale,serverURL:"https://waline.17lai.site",path:"/posts/a0f3c838/",avatar:"mp",emoji:["//fastly.jsdelivr.net/gh/walinejs/emojis@latest/weibo"],lang:"zh-CN",dark:'html[data-user-color-scheme="dark"]',login:"enable",wordLimit:"1000",pageSize:"10",highlighter:(e,n)=>(window.Prism.languages[n]||window.Prism.plugins.autoloader.loadLanguages(n),window.Prism.highlight(e,window.Prism.languages[n]||window.Prism.languages.text,n)),pageview:!1,comment:!0,reaction:["https://testingcf.jsdelivr.net/npm/@waline/emojis/tieba/tieba_agree.png","https://testingcf.jsdelivr.net/npm/@waline/emojis/tieba/tieba_look_down.png","https://testingcf.jsdelivr.net/npm/@waline/emojis/tieba/tieba_sunglasses.png","https://testingcf.jsdelivr.net/npm/@waline/emojis/tieba/tieba_pick_nose.png","https://testingcf.jsdelivr.net/npm/@waline/emojis/tieba/tieba_awkward.png","https://testingcf.jsdelivr.net/npm/@waline/emojis/tieba/tieba_sleep.png"],search:!1,imageUploader:!1,meta:["nick","mail","link"],recaptchaV3Key:"6LeUY0MiAAAAABNBvi6m4PcCtKkv_W6x-_YhTb6n",requiredMeta:["nick","mail"]}),document.getElementById("loading_data").style.display="none";{function e(){const e=commentCount({serverURL:"https://waline.17lai.site",path:"/posts/a0f3c838/"});setTimeout(()=>e(),2e3);try{wa_ccc="waline_comments_count",document.getElementById(wa_ccc).style.display="inline-block"}catch(e){console.log("[waline-count][Error] err")}console.log("[waline]update comment count!")}function n(){setTimeout((function(){e()}),5e3),console.log("[waline]delay update comment count!")}try{var i=document.body.getElementsByClassName("wl-btn primary");void 0!==i[0]?(void 0!==window.addEventListener?i[0].addEventListener("click",n,!1):i[0].attachEvent("onclick",n),e()):console.log("[waline]没有登录waline!")}catch(e){console.error("An error occurred while handling the element:",e)}}AOS.refresh(),progressBarInit()}function loadWaline(){try{const e=document.createElement("link");e.rel="stylesheet",e.href="/libs/waline/waline.min.css?v=3.5.4",document.head.appendChild(e);import("/libs/waline/waline.min.js?v=3.5.4").then(()=>{initWaline()}).catch(e=>{console.error("Failed to load waline script:",e)})}catch(e){console.log("[SHARE][Error] Failed to load Waline:",e)}}var runningOnBrowser="undefined"!=typeof window,isBot=runningOnBrowser&&!("onscroll"in window)||"undefined"!=typeof navigator&&/(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo/i.test(navigator.userAgent),supportsIntersectionObserver=runningOnBrowser&&"IntersectionObserver"in window;setTimeout((function(){if(!isBot&&supportsIntersectionObserver){var e=new IntersectionObserver((function(n){n[0].isIntersecting&&(loadWaline(),e.disconnect())}),{threshold:[0]});e.observe(document.getElementById("comments"))}else loadWaline()}),1)</script><script>AOS.refresh(),progressBarInit()</script><script>function loadShare(){try{jQuery.ajax({url:"/libs/share/js/social-share.min.js?v=1.0.16",dataType:"script",cache:!0,success:function(){}})}catch(e){console.log("[SHARE][Error] JQuery is not defined.")}}var runningOnBrowser="undefined"!=typeof window,isBot=runningOnBrowser&&!("onscroll"in window)||"undefined"!=typeof navigator&&/(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo/i.test(navigator.userAgent),supportsIntersectionObserver=runningOnBrowser&&"IntersectionObserver"in window;setTimeout((function(){if(!isBot&&supportsIntersectionObserver){var e=new IntersectionObserver((function(n){n[0].isIntersecting&&(loadShare(),e.disconnect())}),{threshold:[0]});e.observe(document.getElementById("article-share"))}else loadShare()}),1)</script><script type="text/javascript" defer>progressBarInit()</script><script type="text/javascript" size="150" alpha="0.6" zindex="-1" src="/libs/background/ribbon.min.js" async></script><script defer src="/libs/prism/components/prism-core.min.js"></script><script defer src="/libs/prism/plugins/autoloader/prism-autoloader.min.js"></script><script defer src="/libs/prism/plugins/line-numbers/prism-line-numbers.min.js"></script><script>Matery.plugins.codeWidget()</script><script defer src="/libs/instantpage/instantpage.min.js" type="module" importance="low"></script><script src="/js/boot.js?v=1.0.0"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript><script src="/assets/mmedia/mmedia-loader.js"></script><script defer>if (localStorage.viewCount > 1) {
            (function (w, d, s, id) {
            if (typeof (w.webpushr) !== 'undefined' || isBot) return; 
            w.webpushr = w.webpushr || function () { (w.webpushr.q = w.webpushr.q || []).push(arguments) }; 
            var js, fjs = d.getElementsByTagName(s)[0]; 
            js = d.createElement(s); 
            js.id = id; 
            js.async = true; 
            js.src = "https://cdn.webpushr.com/app.min.js";
            fjs.parentNode.appendChild(js);
            }(window, document, 'script', 'webpushr-jssdk'));
            webpushr('setup', { 'key': 'BDHamjevXR9yPJrttxl80MjCYEwm3CKzwsi3rwMXxq4Lnbzhr2fNQARqXJVhfBn_ucmy9QHixa3qps8eEFXBwmw' });
        }</script></body></html>